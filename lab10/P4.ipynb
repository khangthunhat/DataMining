{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f7/qm1l4pnj4zngs_4y69yv1g9c0000gn/T/ipykernel_53858/1722914141.py:1: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('ThiTHPT2018.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": "          SoBD  Toan   Van  Anh    Ly   Hoa  Sinh   Su   Dia  GDCD  \\\n0            1   3.0  3.75  3.0   NaN   NaN   NaN  3.0  6.50  8.25   \n1            2   8.8  7.50  9.0   NaN   NaN   NaN  6.0  9.00  8.25   \n2            3   6.0  5.50  4.0  5.75  5.50  5.00  NaN   NaN   NaN   \n3            4   3.4  5.75  2.6   NaN   NaN   NaN  3.5  4.75  7.25   \n4            5   3.8  6.75  3.0   NaN   NaN   NaN  3.5  6.25  8.00   \n...        ...   ...   ...  ...   ...   ...   ...  ...   ...   ...   \n744391  744392   4.6  4.50  6.0  3.75  3.00  3.25  NaN   NaN   NaN   \n744392  744393   7.0  6.00  5.0  5.25  5.50  4.00  NaN   NaN   NaN   \n744393  744394   5.2  3.50  4.0  6.25  5.50  2.25  NaN   NaN   NaN   \n744394  744395   7.8  4.50  5.4  7.50  6.25  3.00  NaN   NaN   NaN   \n744395  744396   5.8  3.50  3.0  6.25  4.75  3.25  NaN   NaN   NaN   \n\n        Unnamed: 10  KhoiA  KhoiB  KhoiC  KhoiD  KhoiA1  Ma Tinh  \\\n0               NaN    NaN    NaN  13.25   9.75     NaN       18   \n1               NaN    NaN    NaN  22.50   25.3     NaN       18   \n2               NaN  17.25  16.50    NaN   15.5   15.75       18   \n3               NaN    NaN    NaN  14.00  11.75     NaN       18   \n4               NaN    NaN    NaN  16.50  13.55     NaN       18   \n...             ...    ...    ...    ...    ...     ...      ...   \n744391          NaN  11.35  10.85    NaN   15.1   14.35       52   \n744392          NaN  17.75  16.50    NaN     18   17.25       52   \n744393          NaN  16.95  12.95    NaN   12.7   15.45       52   \n744394          NaN  21.55  17.05    NaN   17.7   20.70       52   \n744395          NaN  16.80  13.80    NaN   12.3   15.05       52   \n\n                Ten Tinh Vung mien  \n0              Bac Giang  Mien Bac  \n1              Bac Giang  Mien Bac  \n2              Bac Giang  Mien Bac  \n3              Bac Giang  Mien Bac  \n4              Bac Giang  Mien Bac  \n...                  ...       ...  \n744391   Ba Ria Vung Tau  Mien Nam  \n744392   Ba Ria Vung Tau  Mien Nam  \n744393   Ba Ria Vung Tau  Mien Nam  \n744394   Ba Ria Vung Tau  Mien Nam  \n744395   Ba Ria Vung Tau  Mien Nam  \n\n[744396 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SoBD</th>\n      <th>Toan</th>\n      <th>Van</th>\n      <th>Anh</th>\n      <th>Ly</th>\n      <th>Hoa</th>\n      <th>Sinh</th>\n      <th>Su</th>\n      <th>Dia</th>\n      <th>GDCD</th>\n      <th>Unnamed: 10</th>\n      <th>KhoiA</th>\n      <th>KhoiB</th>\n      <th>KhoiC</th>\n      <th>KhoiD</th>\n      <th>KhoiA1</th>\n      <th>Ma Tinh</th>\n      <th>Ten Tinh</th>\n      <th>Vung mien</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3.0</td>\n      <td>3.75</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>6.50</td>\n      <td>8.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.25</td>\n      <td>9.75</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>Bac Giang</td>\n      <td>Mien Bac</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>8.8</td>\n      <td>7.50</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>9.00</td>\n      <td>8.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22.50</td>\n      <td>25.3</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>Bac Giang</td>\n      <td>Mien Bac</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>6.0</td>\n      <td>5.50</td>\n      <td>4.0</td>\n      <td>5.75</td>\n      <td>5.50</td>\n      <td>5.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.25</td>\n      <td>16.50</td>\n      <td>NaN</td>\n      <td>15.5</td>\n      <td>15.75</td>\n      <td>18</td>\n      <td>Bac Giang</td>\n      <td>Mien Bac</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3.4</td>\n      <td>5.75</td>\n      <td>2.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.5</td>\n      <td>4.75</td>\n      <td>7.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.00</td>\n      <td>11.75</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>Bac Giang</td>\n      <td>Mien Bac</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3.8</td>\n      <td>6.75</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.5</td>\n      <td>6.25</td>\n      <td>8.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.50</td>\n      <td>13.55</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>Bac Giang</td>\n      <td>Mien Bac</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>744391</th>\n      <td>744392</td>\n      <td>4.6</td>\n      <td>4.50</td>\n      <td>6.0</td>\n      <td>3.75</td>\n      <td>3.00</td>\n      <td>3.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.35</td>\n      <td>10.85</td>\n      <td>NaN</td>\n      <td>15.1</td>\n      <td>14.35</td>\n      <td>52</td>\n      <td>Ba Ria Vung Tau</td>\n      <td>Mien Nam</td>\n    </tr>\n    <tr>\n      <th>744392</th>\n      <td>744393</td>\n      <td>7.0</td>\n      <td>6.00</td>\n      <td>5.0</td>\n      <td>5.25</td>\n      <td>5.50</td>\n      <td>4.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.75</td>\n      <td>16.50</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>17.25</td>\n      <td>52</td>\n      <td>Ba Ria Vung Tau</td>\n      <td>Mien Nam</td>\n    </tr>\n    <tr>\n      <th>744393</th>\n      <td>744394</td>\n      <td>5.2</td>\n      <td>3.50</td>\n      <td>4.0</td>\n      <td>6.25</td>\n      <td>5.50</td>\n      <td>2.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.95</td>\n      <td>12.95</td>\n      <td>NaN</td>\n      <td>12.7</td>\n      <td>15.45</td>\n      <td>52</td>\n      <td>Ba Ria Vung Tau</td>\n      <td>Mien Nam</td>\n    </tr>\n    <tr>\n      <th>744394</th>\n      <td>744395</td>\n      <td>7.8</td>\n      <td>4.50</td>\n      <td>5.4</td>\n      <td>7.50</td>\n      <td>6.25</td>\n      <td>3.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.55</td>\n      <td>17.05</td>\n      <td>NaN</td>\n      <td>17.7</td>\n      <td>20.70</td>\n      <td>52</td>\n      <td>Ba Ria Vung Tau</td>\n      <td>Mien Nam</td>\n    </tr>\n    <tr>\n      <th>744395</th>\n      <td>744396</td>\n      <td>5.8</td>\n      <td>3.50</td>\n      <td>3.0</td>\n      <td>6.25</td>\n      <td>4.75</td>\n      <td>3.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.80</td>\n      <td>13.80</td>\n      <td>NaN</td>\n      <td>12.3</td>\n      <td>15.05</td>\n      <td>52</td>\n      <td>Ba Ria Vung Tau</td>\n      <td>Mien Nam</td>\n    </tr>\n  </tbody>\n</table>\n<p>744396 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ThiTHPT2018.csv')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 744396 entries, 0 to 744395\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   SoBD         744396 non-null  int64  \n",
      " 1   Toan         741024 non-null  float64\n",
      " 2   Van          728309 non-null  float64\n",
      " 3   Anh          659998 non-null  float64\n",
      " 4   Ly           323353 non-null  float64\n",
      " 5   Hoa          326981 non-null  float64\n",
      " 6   Sinh         319605 non-null  float64\n",
      " 7   Su           446118 non-null  float64\n",
      " 8   Dia          433221 non-null  float64\n",
      " 9   GDCD         379034 non-null  float64\n",
      " 10  Unnamed: 10  0 non-null       float64\n",
      " 11  KhoiA        321232 non-null  float64\n",
      " 12  KhoiB        319516 non-null  float64\n",
      " 13  KhoiC        432605 non-null  float64\n",
      " 14  KhoiD        656353 non-null  object \n",
      " 15  KhoiA1       307864 non-null  float64\n",
      " 16  Ma Tinh      744396 non-null  int64  \n",
      " 17  Ten Tinh     744396 non-null  object \n",
      " 18  Vung mien    744396 non-null  object \n",
      "dtypes: float64(14), int64(2), object(3)\n",
      "memory usage: 107.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "SoBD                0\nToan             3372\nVan             16087\nAnh             84398\nLy             421043\nHoa            417415\nSinh           424791\nSu             298278\nDia            311175\nGDCD           365362\nUnnamed: 10    744396\nKhoiA          423164\nKhoiB          424880\nKhoiC          311791\nKhoiD           88043\nKhoiA1         436532\nMa Tinh             0\nTen Tinh            0\nVung mien           0\ndtype: int64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "# Replacing null value with mean of Toan Attribute\n",
    "data1['Toan'].fillna(data1['Toan'].mean(), inplace= True)\n",
    "data1['Van'].fillna(data1['Van'].mode()[0], inplace=True)\n",
    "data1['Anh'] = data1.groupby(['Ten Tinh'], group_keys=False)['Anh'].apply(lambda x: x.fillna(x.mode()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "\n",
    "# tính số giá trị thiếu cho từng cột\n",
    "missing_values = data1.isnull().sum()\n",
    "\n",
    "# tính tổng số giá trị trong DataFrame\n",
    "total_values = np.product(data1.shape)\n",
    "\n",
    "# tính tỷ lệ giá trị thiếu cho từng cột\n",
    "missing_ratio = missing_values / total_values\n",
    "\n",
    "# xác định các cột có tỷ lệ giá trị thiếu >= 0.5\n",
    "cols_to_drop = missing_ratio[missing_ratio >= 0.5].index.tolist()\n",
    "\n",
    "# xóa các cột có tỷ lệ giá trị thiếu >= 0.5\n",
    "data1 = data1.drop(cols_to_drop, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "data1.dropna(axis=1, how='all',inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "#điền giá trị '0' cho những ô bị thiếu\n",
    "data1.fillna('0',inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "data1.dropna(subset=['Hoa', 'Ly', 'Dia'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "SoBD         0\nToan         0\nVan          0\nAnh          0\nLy           0\nHoa          0\nSinh         0\nSu           0\nDia          0\nGDCD         0\nKhoiA        0\nKhoiB        0\nKhoiC        0\nKhoiD        0\nKhoiA1       0\nMa Tinh      0\nTen Tinh     0\nVung mien    0\ndtype: int64"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "SoBD         0\nToan         0\nVan          0\nAnh          0\nLy           0\nHoa          0\nSinh         0\nSu           0\nDia          0\nGDCD         0\nKhoiA        0\nKhoiB        0\nKhoiC        0\nKhoiD        0\nKhoiA1       0\nMa Tinh      0\nTen Tinh     0\nVung mien    0\ndtype: int64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_df = data1.isna()\n",
    "count_nan = isna_df.sum()\n",
    "count_nan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "scores_A = data.loc[:, ['Toan', 'Ly', 'Hoa']]\n",
    "scores_A1 = data.loc[:, ['Toan', 'Ly', 'Anh']]\n",
    "scores_B = data.loc[:, ['Toan', 'Hoa', 'Sinh']]\n",
    "scores_C = data.loc[:, ['Van', 'Su', 'Dia']]\n",
    "scores_D = data.loc[:, ['Van', 'Toan', 'Anh', 'Su', 'Dia']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "scaler_A = StandardScaler().fit(scores_A)\n",
    "scores_A_scaled = scaler_A.transform(scores_A)\n",
    "\n",
    "scaler_A1 = StandardScaler().fit(scores_A1)\n",
    "scores_A1_scaled = scaler_A1.transform(scores_A1)\n",
    "\n",
    "scaler_B = StandardScaler().fit(scores_B)\n",
    "scores_B_scaled = scaler_B.transform(scores_B)\n",
    "\n",
    "scaler_C = StandardScaler().fit(scores_C)\n",
    "scores_C_scaled = scaler_C.transform(scores_C)\n",
    "\n",
    "scaler_D = StandardScaler().fit(scores_D)\n",
    "scores_D_scaled = scaler_D.transform(scores_D)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m kmeans_A \u001B[38;5;241m=\u001B[39m KMeans(n_clusters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mfit(scores_A_scaled)\n\u001B[0;32m----> 2\u001B[0m kmeans_A1 \u001B[38;5;241m=\u001B[39m \u001B[43mKMeans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscores_A1_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m kmeans_B \u001B[38;5;241m=\u001B[39m KMeans(n_clusters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mfit(scores_B_scaled)\n\u001B[1;32m      4\u001B[0m kmeans_C \u001B[38;5;241m=\u001B[39m KMeans(n_clusters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mfit(scores_C_scaled)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1417\u001B[0m, in \u001B[0;36mKMeans.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute k-means clustering.\u001B[39;00m\n\u001B[1;32m   1391\u001B[0m \n\u001B[1;32m   1392\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1413\u001B[0m \u001B[38;5;124;03m    Fitted estimator.\u001B[39;00m\n\u001B[1;32m   1414\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1415\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m-> 1417\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1418\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1419\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1420\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1421\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1422\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1423\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1424\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_params_vs_input(X)\n\u001B[1;32m   1428\u001B[0m random_state \u001B[38;5;241m=\u001B[39m check_random_state(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:546\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    545\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 546\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    547\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    548\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    918\u001B[0m         )\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 921\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m     )\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "kmeans_A = KMeans(n_clusters=3).fit(scores_A_scaled)\n",
    "kmeans_A1 = KMeans(n_clusters=3).fit(scores_A1_scaled)\n",
    "kmeans_B = KMeans(n_clusters=3).fit(scores_B_scaled)\n",
    "kmeans_C = KMeans(n_clusters=3).fit(scores_C_scaled)\n",
    "kmeans_D = KMeans(n_clusters=3).fit(scores_D_scaled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
